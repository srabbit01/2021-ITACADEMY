{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4978a7",
   "metadata": {},
   "source": [
    "1. 검색 → 뉴스탭 가서 → 요약본: 제목/내용/신문사/개시시간 긁기\n",
    "2. 사용자에게 검색건수를 입력 받아서 페이지 넘기기\n",
    "3. 1번과 3번을 이용해서 사용자에게 검색건수를 입력 받아서 나오는 페이지 수만큼 요약정보 가져오기\n",
    "4. 상세 페이지 크롤링하기\n",
    "5. 결과물 첫 페이지에 있는 본문들 차례대로 클릭해서 들어가기 → drive.back() 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94a12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1. 필요한 모듈과 라이브러리를 import 합니다\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import math\n",
    "import numpy  \n",
    "import pandas as pd  \n",
    "import xlwt\n",
    "\n",
    "#Step 2. 필요한 정보를 입력 받습니다\n",
    "# query_txt = input('1.크롤링할 키워드는 무엇입니까?: ')\n",
    "query_txt= '겨울'\n",
    "\n",
    "# cnt = int(input('2.크롤링 할 건수는 몇건입니까?: '))\n",
    "cnt = 12\n",
    "page_cnt = math.ceil(cnt / 10)  # 크롤링 할 전체 페이지 수 \n",
    "\n",
    "# f_name = input('3.txt 형태로 저장할 경로와 파일명을 확장자 포함해서 쓰세요: ')\n",
    "# fc_name = input('4.csv 형태로 저장할 경로와 파일명을 확장자 포함해서 쓰세요: ')\n",
    "# fx_name = input('5.xls 형태로 저장할 경로와 파일명을 확장자 포함해서 쓰세요: ')\n",
    "\n",
    "#Step 3. 크롬 드라이버를 사용해서 웹 브라우저를 실행합니다.\n",
    "s_time = time.time( ) # 현재 시간을 표기하는 코드 (나중에 파일을 만들때 이름이 겹치면 곤란하기 때문에 현재 시간으로 구분)\n",
    "path = \"c:/temp/chromedriver_94/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "driver.get('https://korean.visitkorea.or.kr/main/main.html')\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "#Step 4. 검색창의 이름을 찾아서 검색어를 입력 후 검색을 진행합니다\n",
    "# driver.find_element_by_id(\"btnSearch\").click()\n",
    "element = driver.find_element_by_id(\"inp_search\")\n",
    "element.send_keys(query_txt) # 위의 입력 값을 변수로 지정해 둔 것이다.\n",
    "element.send_keys('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06987a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 목표 2: 페이지 이동하기\n",
    "#Step 6. 페이지 번호를 바꾸면서 실제 데이터 추출하기\n",
    "\n",
    "no = 1            # 게시글 번호 카운트용 변수\n",
    "\n",
    "no2 =[ ]          # 게시글 번호 저장용 리스트\n",
    "contents2=[ ]     # 게시글 내용 저장용 리스트\n",
    "tags2=[ ]         # 해쉬 태그 정보 저장용 리스트\n",
    "\n",
    "for x in range(1,page_cnt+1) :  # 1페이지부터 반복 시작    \n",
    "    print(\"%s 페이지 내용 수집 시작합니다 =======================\" %x)\n",
    "    print(\"\\n\")    \n",
    "    time.sleep(2)              #페이지가 로딩 될 때까지 2초 대기\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    content_list = soup.find('ul','list_thumType type1').find_all('div','area_txt')\n",
    "    \n",
    "    for i in content_list:  \n",
    "        f_name = \"c:\\\\temp\\\\test2.txt\"\n",
    "\n",
    "        f = open(f_name, 'a',encoding='UTF-8')\n",
    "        \n",
    "        # 게시글 번호 입력\n",
    "        no2.append(no)\n",
    "        print('1.번호:',no)\n",
    "        f.write(\"1.번호:\"+str(no)+\"\\n\")\n",
    "    \n",
    "        # 게시글의 내용 추출 및 입력\n",
    "        contents = i.find('div','tit').get_text( )\n",
    "        contents2.append(contents)\n",
    "        print('2.요약내용:',contents.strip())\n",
    "        f.write(\"2.요약내용:\" + contents + \"\\n\")\n",
    "    \n",
    "        #학습목표 3: 예외 처리 사용하기\n",
    "        try :\n",
    "            tag = i.find('p','tag').get_text()\n",
    "        except AttributeError :\n",
    "            tag = '태그정보가 없습니다'\n",
    "            tags2.append(tag)\n",
    "            print('3.해쉬태그:',tag.strip())\n",
    "            print(\"\\n\")       \n",
    "            f.write(\"3.해쉬태그:\"+tag+\"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        else :\n",
    "            tags2.append(tag)\n",
    "            print('3.해쉬태그:',tag.strip())\n",
    "            print(\"\\n\")\n",
    "            f.write(\"3.해쉬태그:\"+tag+\"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            f.close()\n",
    "            \n",
    "        no += 1\n",
    "        \n",
    "    time.sleep(2)        # 페이지 변경 전 2초 대기 \n",
    "    x += 1       # 다음 페이지를 넘기게 되면 클릭하기 위해 사용 # for loop에 들어가면 초기화\n",
    "    \n",
    "    if x == 6 :\n",
    "        driver.find_element_by_xpath(\"\"\"//*[@id=\"6\"]\"\"\").click()\n",
    "    else :\n",
    "        driver.find_element_by_link_text(\"\"\"%s\"\"\" %x).click()     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2779e2e4",
   "metadata": {},
   "source": [
    "실습) 서울 대기환경정보 사이트에서 2021년 대기오염 물질 분석하기\n",
    "action = ActionChains(driver)\n",
    "action.move_to_element(air_bar).perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ae2e616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_1720/2108256417.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(chrome_path)\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_1720/2108256417.py:13: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  exit = driver.find_element_by_xpath(\"//*[@id='mainPopup']/div/a\")\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_1720/2108256417.py:16: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  bar = driver.find_element_by_xpath(\"//*[@id='main-menu-pc']/li[1]/a\")\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_1720/2108256417.py:18: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  air_bar = driver.find_element_by_xpath(\"//*[@id='page-contents']/div/section[1]/ul/li[2]/a\")\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_1720/2108256417.py:21: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  air_ave = driver.find_element_by_xpath(\"//*[@id='page-contents']/div/section[1]/ul/li[2]/ul/li[3]/a\")\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_1720/2108256417.py:23: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  month_bar = driver.find_element_by_xpath(\"//*[@id='page-contents']/div/section[1]/ul/li[4]/a\")\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_1720/2108256417.py:26: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  month = driver.find_element_by_xpath(\"//*[@id='page-contents']/div/section[1]/ul/li[4]/ul/li[2]/a\")\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "# 서울 대기환경정보 창 열기\n",
    "from selenium import webdriver\n",
    "chrome_path = 'E:\\\\py_temp\\\\WebCrawling\\\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "url = 'https://cleanair.seoul.go.kr'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "import time\n",
    "time.sleep(2)\n",
    "exit = driver.find_element_by_xpath(\"//*[@id='mainPopup']/div/a\")\n",
    "exit.click()\n",
    "# 검색창에 '대기질 실시간 정보' 들어가기\n",
    "bar = driver.find_element_by_xpath(\"//*[@id='main-menu-pc']/li[1]/a\")\n",
    "bar.click()\n",
    "air_bar = driver.find_element_by_xpath(\"//*[@id='page-contents']/div/section[1]/ul/li[2]/a\")\n",
    "action = ActionChains(driver)\n",
    "action.move_to_element(air_bar).perform()\n",
    "air_ave = driver.find_element_by_xpath(\"//*[@id='page-contents']/div/section[1]/ul/li[2]/ul/li[3]/a\")\n",
    "air_ave.click()\n",
    "month_bar = driver.find_element_by_xpath(\"//*[@id='page-contents']/div/section[1]/ul/li[4]/a\")\n",
    "action = ActionChains(driver)\n",
    "action.move_to_element(month_bar).perform()\n",
    "month = driver.find_element_by_xpath(\"//*[@id='page-contents']/div/section[1]/ul/li[4]/ul/li[2]/a\")\n",
    "month.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7186c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_():\n",
    "    full_html = driver.page_source\n",
    "    soup = BeautifulSoup(full_html,'html.parser')\n",
    "    content_list = soup.find('div',id=\"month-table-div\")\n",
    "    li_list = content_list.find('table',id='month-table')\n",
    "    each_month = li_list.find('tr','total').find_all('td')\n",
    "    for i in range(2,14):\n",
    "        try:\n",
    "            month_ave = each_month[i].text.strip()\n",
    "            pollutants[x].append(month_ave)\n",
    "        except:\n",
    "            pollutants[x].append(\"-\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8117e572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_1720/2957796661.py:13: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  type_ = driver.find_element_by_xpath(\"//*[@id='pollutantType']\")\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_1720/2957796661.py:16: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  poll_type = driver.find_element_by_xpath(\"//*[@id='pollutantType']/option[%s]\" %(x+1))\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_1720/2957796661.py:19: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  type_click = driver.find_element_by_id('search')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1월 대기오염물질 평균\n",
      "1. PM2.5: 21\n",
      "2. PM10: 38\n",
      "3. O3: 0.015\n",
      "4. NO2: 0.031\n",
      "5. CO: 0.6\n",
      "6. SO2: 0.004\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "2월 대기오염물질 평균\n",
      "1. PM2.5: 21\n",
      "2. PM10: 38\n",
      "3. O3: 0.015\n",
      "4. NO2: 0.031\n",
      "5. CO: 0.6\n",
      "6. SO2: 0.004\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "3월 대기오염물질 평균\n",
      "1. PM2.5: 21\n",
      "2. PM10: 38\n",
      "3. O3: 0.015\n",
      "4. NO2: 0.031\n",
      "5. CO: 0.6\n",
      "6. SO2: 0.004\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "4월 대기오염물질 평균\n",
      "1. PM2.5: 21\n",
      "2. PM10: 38\n",
      "3. O3: 0.015\n",
      "4. NO2: 0.031\n",
      "5. CO: 0.6\n",
      "6. SO2: 0.004\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "5월 대기오염물질 평균\n",
      "1. PM2.5: 21\n",
      "2. PM10: 38\n",
      "3. O3: 0.015\n",
      "4. NO2: 0.031\n",
      "5. CO: 0.6\n",
      "6. SO2: 0.004\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "6월 대기오염물질 평균\n",
      "1. PM2.5: 21\n",
      "2. PM10: 38\n",
      "3. O3: 0.015\n",
      "4. NO2: 0.031\n",
      "5. CO: 0.6\n",
      "6. SO2: 0.004\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "7월 대기오염물질 평균\n",
      "1. PM2.5: 21\n",
      "2. PM10: 38\n",
      "3. O3: 0.015\n",
      "4. NO2: 0.031\n",
      "5. CO: 0.6\n",
      "6. SO2: 0.004\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "8월 대기오염물질 평균\n",
      "1. PM2.5: 21\n",
      "2. PM10: 38\n",
      "3. O3: 0.015\n",
      "4. NO2: 0.031\n",
      "5. CO: 0.6\n",
      "6. SO2: 0.004\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "9월 대기오염물질 평균\n",
      "1. PM2.5: 21\n",
      "2. PM10: 38\n",
      "3. O3: 0.015\n",
      "4. NO2: 0.031\n",
      "5. CO: 0.6\n",
      "6. SO2: 0.004\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "10월 대기오염물질 평균\n",
      "1. PM2.5: 21\n",
      "2. PM10: 38\n",
      "3. O3: 0.015\n",
      "4. NO2: 0.031\n",
      "5. CO: 0.6\n",
      "6. SO2: 0.004\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "11월 대기오염물질 평균\n",
      "1. PM2.5: 21\n",
      "2. PM10: 38\n",
      "3. O3: 0.015\n",
      "4. NO2: 0.031\n",
      "5. CO: 0.6\n",
      "6. SO2: 0.004\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "12월 대기오염물질 평균\n",
      "1. PM2.5: 21\n",
      "2. PM10: 38\n",
      "3. O3: 0.015\n",
      "4. NO2: 0.031\n",
      "5. CO: 0.6\n",
      "6. SO2: 0.004\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "PM_2_5 = []\n",
    "PM_10 = []\n",
    "O3 = []\n",
    "NO2 = []\n",
    "CO = []\n",
    "SO2 = []\n",
    "\n",
    "pollutants = [PM_2_5,PM_10,O3,NO2,CO,SO2]\n",
    "\n",
    "for x in range(0,6):\n",
    "    type_ = driver.find_element_by_xpath(\"//*[@id='pollutantType']\")\n",
    "    type_.click()\n",
    "    time.sleep(0.5)\n",
    "    poll_type = driver.find_element_by_xpath(\"//*[@id='pollutantType']/option[%s]\" %(x+1))\n",
    "    poll_type.click()\n",
    "    time.sleep(0.5)\n",
    "    type_click = driver.find_element_by_id('search')\n",
    "    type_click.click()\n",
    "    time.sleep(0.5)\n",
    "    get_()\n",
    "    time.sleep(1)\n",
    "            \n",
    "for r in range(0,len(PM_2_5)):\n",
    "    print('\\n')\n",
    "    print(\"%s월 대기오염물질 평균\" %(r+1))\n",
    "    print(\"1. PM2.5:\", pollutants[0][i])\n",
    "    print(\"2. PM10:\", pollutants[1][i])\n",
    "    print(\"3. O3:\", pollutants[2][i])\n",
    "    print(\"4. NO2:\", pollutants[3][i])\n",
    "    print(\"5. CO:\", pollutants[4][i])\n",
    "    print(\"6. SO2:\", pollutants[5][i])\n",
    "    print('\\n')\n",
    "    print('-'*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
